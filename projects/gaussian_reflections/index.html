<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Gaussian Reflections | Eric Lefort </title> <meta name="author" content="Eric Lefort"> <meta name="description" content="Constrained rendering of reflected gaussians"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://eric-lefort.github.io//projects/gaussian_reflections/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eric</span> Lefort </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Gaussian Reflections</h1> <p class="post-description">Constrained rendering of reflected gaussians</p> </header> <article> <p>A few friends of mine are working on high quality 3d reconstruction for sports broadcasting. The startup is Peripheral Labs out of Toronto and they have developed some impressive demos leveraging dynamic gaussians and numerous additional processing stages to show their proof of concept for NBA broadcasting in 3d for potential new immersive / VR experiences. Regardless, I felt that the demo lacked some visual believability due to the lack of lighting effects on the players, which are inserted into the pretrained background scene after the fact.</p> <div class="row"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/vanilla-480.webp 480w,/assets/img/gaussian-reflections/vanilla-800.webp 800w,/assets/img/gaussian-reflections/vanilla-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/vanilla.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Vanilla 3dgs" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Observe the lack of lighting effects affecting the scene's realism. </div> <p>To address this, I undertook a short 2 week project to explore methods to achieve some new lighting effects, primarily reflections off the ground plane.</p> <h2 id="papers">Papers</h2> <h4 id="gaussianshader">GaussianShader</h4> <p><a href="https://arxiv.org/abs/2311.17977" rel="external nofollow noopener" target="_blank">arxiv</a> | <a href="https://asparagus15.github.io/GaussianShader.github.io/" rel="external nofollow noopener" target="_blank">project page</a></p> <p>One of the first papers in the area of reflections in 3dgs. This paper introduces a heuristic for determining the normal, using the direction of least variance of the gaussian and learns a residual on top of this. Not true reflections—Doesn’t actually perform ray tracing in the scene. Achieves apparent reflections through learning an environment map. (think a low res image of the surroundings, mapped to the inside of a sphere, high fidelity is not assumed to be important because their applications are primarily reflections in curved and irregular objects, where you cannot clearly see the reflected scene anyways) and then querying the environment map with the reflected ray direction. In this case, they learn a 64x64x6 environment map, where the 6 layers match the lighting for different specularity levels. Their shading function is a differentiable function of the scene, including additional learned parameters such as specularity per gaussian. This continuous learned value allow them to interpolate over the environment mip maps.</p> <h4 id="3dgs-with-deferred-reflection">3dgs with deferred reflection</h4> <p><a href="https://arxiv.org/abs/2404.18454" rel="external nofollow noopener" target="_blank">arxiv</a> | <a href="https://gapszju.github.io/3DGS-DR/" rel="external nofollow noopener" target="_blank">project page</a></p> <p>Builds on top of GaussianShader. Start by learning using the vanilla 3dgs method. This provides baseline normal and structural information. Second pass learns a reflectiveness per gaussian and rasterizes the image, reflectiveness and normal map to screen space. They leverage an empirical observation that high-reflectivity gaussians are more likely to be correct and propagate these normals to neighboring gaussians.</p> <p>Both of these previous papers use primarily examples of irregular shapes with reflective surfaces in the middle of a scene. This is a relatively low accuracy, and unconstrained problem.</p> <h4 id="mirrorgaussian">MirrorGaussian</h4> <p><a href="https://arxiv.org/abs/2405.11921" rel="external nofollow noopener" target="_blank">arxiv</a> | <a href="https://mirror-gaussian.github.io/" rel="external nofollow noopener" target="_blank">project page</a></p> <p>This paper learns an additional mirror flag property to the gaussians, which you can rasterize to get a mirror mask. Estimate the plane fit and use it to reflect the whole scene about the mirror. Crop the mirror scene based on the mask. To get an initial guess for mirror points, lift SAM mask to 3d. (After having trained gaussians using vanilla method) Jointly optimize everything together to fine tune. Initial training is done with ground truth SAM masks, until mirror plane is optimized, then switch to masks from rasterized mirror flag / label</p> <p>This paper focuses more on applications similar to what Peripheral needs. It is much more constrained but higher accuracy compared to the previous papers.</p> <h4 id="3d-gaussian-unscented-transform">3d Gaussian Unscented Transform</h4> <p><a href="https://arxiv.org/abs/2412.12507" rel="external nofollow noopener" target="_blank">arxiv</a> | <a href="https://research.nvidia.com/labs/toronto-ai/3DGUT/" rel="external nofollow noopener" target="_blank">project page</a> | <a href="https://github.com/nv-tlabs/3dgrut" rel="external nofollow noopener" target="_blank">github</a></p> <p>In 3dgs, you need to take 3d gaussians to 2d image space. Instead of using a linearization of the affine 3D to 2D projection which gives errors even for pinhole camera model, use 2N+1 sigma points. Apply transformation, recover approximate transformed distribution from transformed sigma points. Based on OG unscented kalman filtering paper. This makes it flexible for many more projections functions that are highly nonlinear, like fisheye cameras. UT avoids having to backprop through the projection function by sampling the color values directly in 3d space. Trace a ray for a pixel. Computes the maximum response along that ray for each gaussian (call this the maximum response point). Sorts them using “MLAB” formulation to get the accurate z-sort (ie based on tau_max instead of means). The challenge is to leverage the fact that they are already sorted by tile (by their means) in 3dgs so you need to perform additional steps on top of that to correct the sort by the max response point.</p> <p>What about reflections? Reflections are possible with this method because it produces renders consistent with 3d-grt and you can level tau_max along with normal information to perform this ray tracing. Compared to vanilla 3dgs you can get this “intersection point” (tau max) and ray trace from there. The paper also claims that they have “aligned” the rendering method from 3d-gut with that from 3d-grt, likely because of their qualitatively similar output and this additional geometric / surface information you can get out, allowing potential ray tracing. Note that reflectivity and other such demonstrated properties are not actually trained into the scene.</p> <h2 id="project">Project</h2> <p>In the end, I decided to focus on running the dataset through the 3d-GRUT pipeline to verify that it would be possible, given the scale of the dataset. This preliminary work will facilitate future improvements that can leverage 3D-GRUT’s support for secondary rays. This pipeline also enable more computationally efficient capture through the use of fisheye cameras.</p> <p>Furthermore, I experimented with naive methods for giving the appearance of reflections that would be quick to prototype. This involves mirroring the players below the ground plane, and is inspired by the fact that the model learns to do this with certain features, like the net, during optimization, to give this appearance of reflections.</p> <div class="row"> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/vanilla_vs_3dgut-480.webp 480w,/assets/img/gaussian-reflections/vanilla_vs_3dgut-800.webp 800w,/assets/img/gaussian-reflections/vanilla_vs_3dgut-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/vanilla_vs_3dgut.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="cloud-compute">Cloud compute</h2> <p>This was my first time using Nvidia Brev and one of the first times I used cloud compute in general.</p> <p>I primarily used the A10G and A100 GPUs with the following specs:</p> <table> <thead> <tr> <th>Specification</th> <th>NVIDIA A10G</th> <th>NVIDIA A100</th> </tr> </thead> <tbody> <tr> <td>Memory Size</td> <td>24 GB GDDR6</td> <td>40 GB or 80 GB HBM2e</td> </tr> <tr> <td>Memory Bandwidth</td> <td>600 GB/s</td> <td>&gt; 2 TB/s (≈ 2000 GB/s)</td> </tr> <tr> <td>Tensor Cores</td> <td>320 (3rd-Gen Tensor Cores)</td> <td>512 (3rd-Gen Tensor Cores)</td> </tr> <tr> <td>RT (Ray Tracing) Cores</td> <td>80 (2nd-Gen RT Cores)</td> <td>None</td> </tr> </tbody> </table> <p>An important note, and something that I overlooked initially, is that 3d-GRT <strong>requires</strong> ray tracing hardware and will not be able to run on an A100, for this reason.</p> <p>For the purposes of running 3d-GUT and 3d-GRT on the provided dataset, golden1_bg_colmap_done_noZcams_cleaned_aligned, more than the 20GB provided by an A10G are required, particularly for the rendering / eval operations. This issue is likely able to be overcome by making slight modifications to the way data is loaded into memory at the evaluation stage. If training memory also becomes problematic, a possible solution would be to make a conservative estimate of the maximum batch size that would fit in VRAM at runtime (or hardcoded) and randomly sample batches of the input images of that size. (Likely would want to perform many optimizations steps with each batch to reduce the effect of the memory transfer bottleneck). The A100 is able to handle the entire training + eval procedure, with 2x downsampling, but does not contain ray tracing hardware, making it incompatible with GRT. Image downsampling script with pillow Ran a 2x downsampled version of the dataset and determined configuration that produced reasonably good results with both classic approach and monte carlo (mcmc) sampling. Wrote a script that takes a ply of court / floor gaussians (manually selected), fits a plane, reflects foreground (ie players) gaussians while reducing opacity, brightness and clipping below the plane. Additionally experimented with casting shadows directly on the ground below players.</p> <h2 id="results">Results</h2> <p>Best configuration achieved: 2x downsampled 3d-gut on A100, using mcmc config 0. More configuration tweaking would likely produce improvements, especially for the vanilla sampling approach.</p> <p>Demonstrated the improved realism with a simple reflection approach, and provided scripts that can be used to perform tests on different visual features and analyze what approaches are the most promising, i.e. shadows, reflections, etc.</p> <div class="row"> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/output_1-480.webp 480w,/assets/img/gaussian-reflections/output_1-800.webp 800w,/assets/img/gaussian-reflections/output_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/output_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/output_2-480.webp 480w,/assets/img/gaussian-reflections/output_2-800.webp 800w,/assets/img/gaussian-reflections/output_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/output_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/output_3-480.webp 480w,/assets/img/gaussian-reflections/output_3-800.webp 800w,/assets/img/gaussian-reflections/output_3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/output_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/output_4-480.webp 480w,/assets/img/gaussian-reflections/output_4-800.webp 800w,/assets/img/gaussian-reflections/output_4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/output_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: with "reflected" players inserted in 3d-GUT-trained scene. Right: same scene with no reflected players. We can see some artifacts related to poor regularization of the floor and a few other regions. Despite this, in regions with less court artifacts, such as the key, the appearance of reflections improves realism. </div> <h2 id="going-forward">Going Forward</h2> <p>There remain many low hanging fruit for improving these results.</p> <ul> <li>Continuing to optimize training configurations for gut</li> <li>Optimize memory loading to reduce outOfMemory errors</li> <li>Running trained models in playground to get visual effects. (maybe train a slightly lower fidelity model / take first one I trained, just for proof of concept, large model is causing memory issues on A10G)</li> <li>Incorporating regularization to help flatten ground plane</li> <li>Training GUT with depth regularization</li> </ul> <p>Some more ambitious future projects:</p> <ul> <li>Leveraging prior information about the ground: i.e. that it is flat and combining regularization enforcing this with learned specular / reflective properties, similar to <em>GaussianShader</em> and 3dgs-DR. Experiment with using secondary rays to perform accurate reflection.</li> <li>Many new and interesting papers from SIGGRAPH 2025. Including <em>Echoes of the Coliseum</em>, which implements various stages that may enable faster and smoother optimization of the scene, particularly for real-time applications.</li> <li>Reducing noise on the players, train a model to help bootstrap optimization, explore methods such as Difix3D.</li> </ul> <div class="row"> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian-reflections/real-480.webp 480w,/assets/img/gaussian-reflections/real-800.webp 800w,/assets/img/gaussian-reflections/real-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/gaussian-reflections/real.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A photo from a real NBA game, we can see the specularity of the ground and other effects. </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Eric Lefort. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: August 19, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-atomic-chess-ai",title:"Atomic Chess AI",description:"",section:"Projects",handler:()=>{window.location.href="/projects/atomic_ai/"}},{id:"projects-computational-aerodynamics-group",title:"Computational Aerodynamics Group",description:"Research in meshing and computational fluid dynamics",section:"Projects",handler:()=>{window.location.href="/projects/cfd_lab/"}},{id:"projects-fundamentals-of-computer-vision",title:"Fundamentals of Computer Vision",description:"Learning to process image input",section:"Projects",handler:()=>{window.location.href="/projects/computer_vision_basics/"}},{id:"projects-gaussian-reflections",title:"Gaussian Reflections",description:"Constrained rendering of reflected gaussians",section:"Projects",handler:()=>{window.location.href="/projects/gaussian_reflections/"}},{id:"projects-robotic-lego-manipulation",title:"Robotic Lego Manipulation",description:"Research in Munich",section:"Projects",handler:()=>{window.location.href="/projects/lsy_lego/"}},{id:"projects-reinforcement-learning",title:"Reinforcement Learning",description:"Research in Munich. How to explore efficiently in highly overactuated environments",section:"Projects",handler:()=>{window.location.href="/projects/lsy_rl/"}},{id:"projects-topographic-map-of-mount-mansfield-vt",title:"Topographic Map of Mount Mansfield, VT",description:"A small personal project to learn GIS and laser cutting",section:"Projects",handler:()=>{window.location.href="/projects/mansfield_map/"}},{id:"projects-ode-particle-simulation",title:"ODE Particle Simulation",description:"Particle motion and rendering with pygame",section:"Projects",handler:()=>{window.location.href="/projects/ode_particle_sim/"}},{id:"projects-physics-engine",title:"Physics Engine",description:"",section:"Projects",handler:()=>{window.location.href="/projects/physics_engine/"}},{id:"projects-ray-tracing",title:"Ray Tracing",description:"3D modeling and meshing",section:"Projects",handler:()=>{window.location.href="/projects/ray_tracing/"}},{id:"projects-robotic-path-planning",title:"Robotic Path Planning",description:"RRT, RRT*, and Model Predictive Control",section:"Projects",handler:()=>{window.location.href="/projects/rob521_mobile_robotics/"}},{id:"projects-seam-carving",title:"Seam Carving",description:"Content-Aware Image Resizing",section:"Projects",handler:()=>{window.location.href="/projects/seam_carving/"}},{id:"projects-undergraduate-thesis",title:"Undergraduate Thesis",description:"3D Reconstruction of Articulated Objects",section:"Projects",handler:()=>{window.location.href="/projects/thesis_3d_reconstruction/"}},{id:"projects-turtlebot-racing",title:"Turtlebot Racing",description:"PID controllers and bayesian localization",section:"Projects",handler:()=>{window.location.href="/projects/turtlebot/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%65%72%69%63.%6C%65%66%6F%72%74%38@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/ericlefort1","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>