<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Undergraduate Thesis | Eric Lefort </title> <meta name="author" content="Eric Lefort"> <meta name="description" content="3D Reconstruction of Articulated Objects"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://eric-lefort.github.io//projects/thesis_3d_reconstruction/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eric</span> Lefort </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Undergraduate Thesis</h1> <p class="post-description">3D Reconstruction of Articulated Objects</p> </header> <article> <p>Digital twins let roboticists train or test manipulation policies entirely in simulation before transferring them back to the real world, making them useful in improving scalability and flexibility in robotics development. For my undergraduate thesis, I survey the current landscape in the field of 3D reconstruction and introduce a pipeline for open-vocabulary, object-level method for generation of an articulated mesh purely from monocular RGB videos. The method leverages a 3d scan of the object in question along with a video demonstration of the object’s articulation. The method combines multi-scale semantic segmentation using neural radiance fields (NeRFs) with a 3d Gaussian splatting-based (3DGS) objecting tracking method to create a segmented splat of the object and extract relative poses of each object part. A least-squares hinge-estimation stage then recovers the best-fit revolute joint, allowing the creation of a simulation-ready articulated mesh.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❌ no depth camera

❌ no training required

✅ works with any objects (open-vocabulary)

⚠️ manually specify object for crop

⚠️ manually specify scale for segmentation
</code></pre></div></div> <h2 id="important-papers">Important Papers</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/thesis/render_rgb.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" autoplay="" loop=""></video> </figure> </div> </div> <div class="caption"> RGB render of 3d gaussian splatting model of cooler. </div> <h3 id="group-anything-with-radiance-fields-garfield">Group Anything with Radiance Fields (GARField)</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/garfield_scene-480.webp 480w,/assets/img/thesis/garfield_scene-800.webp 800w,/assets/img/thesis/garfield_scene-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/garfield_scene.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="garfield scene" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><a href="https://www.garfield.studio" rel="external nofollow noopener" target="_blank">GARField</a> addresses the problem of multi-scale 3D segmentation. (e.g., should a jar and its lid be treated as separate parts or a single whole?). Starting from open-vocabulary 2D masks generated by SAM, GARField trains a NeRF that outputs, in addition to colour and density, a scale-conditioned affinity vector. The affinity allows classifying two 3D points as belonging to the same part or not, based on the cosine distance between the vectors.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/garfield_scene_segmented-480.webp 480w,/assets/img/thesis/garfield_scene_segmented-800.webp 800w,/assets/img/thesis/garfield_scene_segmented-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/garfield_scene_segmented.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="garfield scene segmented" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/garfield_parts-480.webp 480w,/assets/img/thesis/garfield_parts-800.webp 800w,/assets/img/thesis/garfield_parts-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/garfield_parts.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="garfield parts" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Pipeline.</p> <ol> <li>Mask harvesting. Each training view is densely queried with SAM, yielding overlapping 2D masks of various sizes. The 2d mask scale is converted to a 3d scale using depth from the NeRF.</li> <li>Scale-conditioned training. For every pair of rays in the same image, the network (i) pulls feature vectors together if the rays lie in the same mask and (ii) pushes them apart otherwise, but only at the scale of that mask. Two auxiliary terms densify supervision along the scale axis (continuous sampling) and enforce containment (small-scale groups must persist at larger scales).</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/multi-scale-masks-480.webp 480w,/assets/img/thesis/multi-scale-masks-800.webp 800w,/assets/img/thesis/multi-scale-masks-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/multi-scale-masks.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="scale-conditioning" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Mechanism for training hierarchical scale-conditioning. </div> <ol> <li>Hierarchy extraction. After convergence, HDBSCAN is run on the affinity field at successively decreasing scales, producing a tree in which parent clusters subdivide into child parts. Users can stop at any depth or interactively click to retrieve a desired granularity</li> </ol> <h3 id="robot-see-robot-do">Robot See Robot Do</h3> <p><a href="https://robot-see-robot-do.github.io" rel="external nofollow noopener" target="_blank">Robot See, Robot Do</a> (RSRD) extends GARField to end-to-end imitation: a dual-arm robot watches a single monocular demonstration and then reproduces the same articulated motion on the physical object. The pipeline assumes two inputs:</p> <ol> <li>An RGB video scan of the object</li> <li>An RGB video demonstrating the object’s articulation (e.g., opening a cooler lid).</li> </ol> <p>4D Differentiable Part Model (4D-DPM). RSRD first trains a GARField scene on the scan video, then selects the object and an appropriate scale to isolate its parts. Those clusters are distilled into a 3DGS augmented with DINO features, yielding a fully differentiable, feature-rich representation. During the demonstration video, the system per-part SE(3) trajectories so that rendered 3DGS features align with the observed frames, using Adam for fifty iterations per timestep, with additional regularization for smoothness. The result is a trajectory consisting of a per-frame for each part.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/thesis/render_rgb.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" autoplay="" loop=""></video> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/thesis/render_dig.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" autoplay="" loop=""></video> </figure> </div> </div> <div class="caption"> RGB render of 3d gaussian splatting model of cooler. On the right are the embedded DINO features for improved object tracking. </div> <p>Imitation Planning. Given these trajectories, a motion planner synthesises dual-arm motions that realise the same part displacements while respecting the robot’s kinematics. Crucially, the planner targets the object frame rather than the demonstrator’s hand pose, allowing grasps that differ from the human’s yet achieve the same functional outcome. The system is validated using a YuMi bimanual robot with nine everyday objects, achieving an average end-to-end success rate of 60 without task-specific training.</p> <h2 id="extension">Extension</h2> <p>After obtaining relative transformations between parts A and B at each time step, we can fit the relative tranformations to a plane using PCA. In the plane, we perform a least-squares circle fit to obtain the pivot point.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/point_cloud_hinge_0-480.webp 480w,/assets/img/thesis/point_cloud_hinge_0-800.webp 800w,/assets/img/thesis/point_cloud_hinge_0-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/point_cloud_hinge_0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="garfield scene segmented" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/thesis/point_cloud_hinge_1-480.webp 480w,/assets/img/thesis/point_cloud_hinge_1-800.webp 800w,/assets/img/thesis/point_cloud_hinge_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/thesis/point_cloud_hinge_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="garfield parts" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visualizing the hinge-fitting process using a point cloud. </div> <p>Now, convert the segmented 3dgs models to meshes using Marching Cubes. We can create a final USD file (or MJCF or similar alternative) constituting the final model, containing the complete object, with articulation.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/thesis/mesh_anim_0.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" autoplay="" loop=""></video> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/thesis/mesh_anim_1.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" autoplay="" loop=""></video> </figure> </div> </div> <div class="caption"> Visualizing the final articulated mesh in IsaacSim. </div> <h2 id="future-improvements">Future Improvements</h2> <h3 id="improved-mesh-reconstruction">Improved Mesh Reconstruction</h3> <p>Marching Cubes sometimes produces poor mesh reconstructions when extracting from a 3dgs in our tests. This is partially caused by the sparse nature of 3dgs models and results in unwanted holes as well as elliptical artifacts un the mesh’s surface. Surface-aligned gaussian splatting for efficient 3d mesh reconstruction (SuGaR) by Guedon et al. describes a better method for reconstructing higher quality meshes that would complement our pipeline well.</p> <h3 id="enhancing-3d-representation-with-diffusion-models">Enhancing 3d Representation with Diffusion Models</h3> <p>Our 3D gaussian splat representation for object parts are prone to two notable effects reducing quality. First, in regions that have few observations or insufficient visually salient features, the 3dgs model sometimes produces unwanted gaussians that protrude from the objects surface or float near it. Next, on parts of the object that are occluded, for example, due to being in contact with a wall or another part of the object, there are also unwanted floating or protruding gaussians.</p> <p>The first issue has been examined in works like Difix3D+, by Wu, Zhang et al., which leverages a diffusion model to denoise rendered views and then uses the improved views to refine the underlying 3dgs. This approach would benefit our pipeline. A promising avenue could be to denoise or potentially complete the unseen parts of objects / object parts, resulting in better quality reconstructions.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Eric Lefort. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: June 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-atomic-chess-ai",title:"Atomic Chess AI",description:"",section:"Projects",handler:()=>{window.location.href="/projects/atomic_ai/"}},{id:"projects-computational-aerodynamics-group",title:"Computational Aerodynamics Group",description:"Research in meshing and computational fluid dynamics",section:"Projects",handler:()=>{window.location.href="/projects/cfd_lab/"}},{id:"projects-fundamentals-of-computer-vision",title:"Fundamentals of Computer Vision",description:"Learning to process image input",section:"Projects",handler:()=>{window.location.href="/projects/computer_vision_basics/"}},{id:"projects-robotic-lego-manipulation",title:"Robotic Lego Manipulation",description:"Research in Munich",section:"Projects",handler:()=>{window.location.href="/projects/lsy_lego/"}},{id:"projects-reinforcement-learning",title:"Reinforcement Learning",description:"Research in Munich. How to explore efficiently in highly overactuated environments",section:"Projects",handler:()=>{window.location.href="/projects/lsy_rl/"}},{id:"projects-topographic-map-of-mount-mansfield-vt",title:"Topographic Map of Mount Mansfield, VT",description:"A small personal project to learn GIS and laser cutting",section:"Projects",handler:()=>{window.location.href="/projects/mansfield_map/"}},{id:"projects-ode-particle-simulation",title:"ODE Particle Simulation",description:"Particle motion and rendering with pygame",section:"Projects",handler:()=>{window.location.href="/projects/ode_particle_sim/"}},{id:"projects-physics-engine",title:"Physics Engine",description:"",section:"Projects",handler:()=>{window.location.href="/projects/physics_engine/"}},{id:"projects-ray-tracing",title:"Ray Tracing",description:"3D modeling and meshing",section:"Projects",handler:()=>{window.location.href="/projects/ray_tracing/"}},{id:"projects-robotic-path-planning",title:"Robotic Path Planning",description:"RRT, RRT*, and Model Predictive Control",section:"Projects",handler:()=>{window.location.href="/projects/rob521_mobile_robotics/"}},{id:"projects-seam-carving",title:"Seam Carving",description:"Content-Aware Image Resizing",section:"Projects",handler:()=>{window.location.href="/projects/seam_carving/"}},{id:"projects-undergraduate-thesis",title:"Undergraduate Thesis",description:"3D Reconstruction of Articulated Objects",section:"Projects",handler:()=>{window.location.href="/projects/thesis_3d_reconstruction/"}},{id:"projects-turtlebot-racing",title:"Turtlebot Racing",description:"PID controllers and bayesian localization",section:"Projects",handler:()=>{window.location.href="/projects/turtlebot/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%65%72%69%63.%6C%65%66%6F%72%74%38@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/ericlefort1","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>